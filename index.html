<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Augustinos Saravanos</title> <meta name="author" content="Augustinos Saravanos"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://asaravanos.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item"> <a class="nav-link" href="https://asaravanos.github.io/assets/pdf/Augustinos_CV_Jan25.pdf" target="\_blank">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Augustinos Saravanos</span>  </h1> <p class="desc">PhD in Machine Learning Student @ <a href="https://sites.gatech.edu/acds/" target="_blank" rel="noopener noreferrer"> ACDS Lab </a>, Georgia Tech</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> 
<div class="clearfix"> <p>I’m a fifth-year PhD in Machine Learning student at Georgia Tech. 
I am fortunate to be part of the <a href="https://sites.gatech.edu/acds/" target="_blank" rel="noopener noreferrer"> Autonomous Control and Decision Systems Lab </a> and to be advised by <a href="https://scholar.google.com/citations?hl=en&user=dG9MV7oAAAAJ" target="_blank" rel="noopener noreferrer"> Prof. Evangelos Theodorou</a>. 

<p>My research lies between <b> optimization </b>, <b>control theory </b> and <b> machine learning </b> towards developing <b> scalable and effective algorithms </b> for <b> large-scale decision-making systems </b>. 

<p>As the scale and complexity of multi-agent systems rapidly increases in many areas, there is an emerging interest in constructing scalable and effective decision making algorithms for such systems. This thesis aims in proposing distributed optimization and control architectures that effectively address such problems, while maintaining scalability and performance guarantees. To achieve this, the outlined completed and proposed research directions combine elements from optimization theory, stochastic optimal control, dynamic optimization, hierarchical architectures and deep learning towards addressing some of the most important current challenges in large-scale decision making, namely, computational efficiency, scalability, guarantees under uncertainty and interpetability. </p>

<ul>
    <li><b>Distributed Dynamic Optimization</b></li>
    <li><b>Distributed Covariance Steering</b></li>
    <li><b>Multi-Agent Deep Forward-Backward SDEs</b></li>
    <li><b>Hierarchical Distribution Optimization</b></li>
    <li><b>Distributed Robust Optimization</b></li>
    <li><b>Deep Distributed Optimization</b></li>
</ul>

<p>During my PhD, I also spent a summer at the <a href="https://www.bosch-ai.com/" target="_blank" rel="noopener noreferrer"> Bosch Center for Artificial Intelligence </a> as a machine learning research intern, where I worked on model alignment and federated learning, under the supervision of <a href="https://scholar.google.com/citations?hl=en&user=kpkMxE8AAAAJ" target="_blank" rel="noopener noreferrer"> Dr. Wan-Yi Lin</a> and <a href="https://scholar.google.com/citations?user=6LYI6uUAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"> Dr. Zhenzhen Li</a>.</p>

<p>Prior to Georgia Tech, I graduated (top 1%) with a Diploma in Electrical and Computer Engineering from the University of Patras in Greece, and was advised by <a href="https://scholar.google.com/citations?hl=en&user=K4FeOr8AAAAJ" target="_blank" rel="noopener noreferrer"> Prof. Evangelos Papadopoulos</a> and <a href="http://www.ece.upatras.gr/index.php/en/ece-faculty/koussoulas-nick.html" target="_blank" rel="noopener noreferrer"> Prof. Nick Koussoulas</a>.</p> <p>See my <b> <a href="https://asaravanos.github.io/assets/pdf/Augustinos_CV_Jan25.pdf" target="_blank">full CV</a> </b> here.</p> <p><b> 

Contact: </b> <a href="mailto:asaravanos3@gatech.edu">asaravanos3 [at] gatech [dot] edu</a></p> </div> 

<p>
<img src="/assets/img/Reseach_Overview_Figure_v2.png" alt="Transparent PNG Logo" style="float: right; margin-left: 10px; width: 100%; height: auto;">
</p>

<div class="publications"> 
<h2>Selected Publications</h2> 
<p class="intro-text">
    * Equal contribution. See <a href="https://scholar.google.com/citations?user=6XP9s1MAAAAJ&hl=en">Google Scholar</a> for full list of publications.
</p>
<ol class="bibliography"> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div> 
<div id="saravanos2024deep" class="col-sm-8"> 
<div class="title"> <font size="+1">Deep Distributed Optimization for Large-Scale Quadratic Programming</font> </div> 
<div class="author"> <strong> <font color="#3B57D3"> A.D. Saravanos</font> </strong>, H. Kuperman, A. Oshin, A.T. Abdul, V. Pacelli and E.A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393"> Preprint (Under review) </font> </em>, 2024 </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2412.12156" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> 
<div class="abstract hidden"> <p>Quadratic programming (QP) forms a crucial foundation in optimization, encompassing a broad spectrum of domains and serving as the basis for more advanced algorithms. Consequently, as the scale and complexity of modern applications continue to grow, the development of efficient and reliable QP algorithms is becoming increasingly vital. In this context, this paper introduces a novel deep learning-aided distributed optimization architecture designed for tackling large-scale QP problems. First, we combine the state-of-the-art Operator Splitting QP (OSQP) method with a consensus approach to derive DistributedQP, a new method tailored for network-structured problems, with convergence guarantees to optimality. Subsequently, we unfold this optimizer into a deep learning framework, leading to DeepDistributedQP, which leverages learned policies to accelerate reaching to desired accuracy within a restricted amount of iterations. Our approach is also theoretically grounded through Probably Approximately Correct (PAC)-Bayes theory, providing generalization bounds on the expected optimality gap for unseen problems. The proposed framework, as well as its centralized version DeepQP, significantly outperform their standard optimization counterparts on a variety of tasks such as randomly generated problems, optimal control, linear regression, transportation networks and others. Notably, DeepDistributedQP demonstrates strong generalization by training on small problems and scaling to solve much larger ones (up to 50K variables and 150K constraints) using the same policy. Moreover, it achieves orders-of-magnitude improvements in wall-clock time compared to OSQP. The certifiable performance guarantees of our approach are also demonstrated, ensuring higher-quality solutions over traditional optimizers.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div> 
<div id="abdul2024robust" class="col-sm-8"> 
<div class="title"> <font size="+1">Scaling Robust Optimization for Multi-Agent Robotic  Systems: A Distributed Perspective</font> </div> 
<div class="author"> A.T. Abdul*, <strong> <font color="#3B57D3"> A.D. Saravanos*</font> </strong> and E.A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393"> Preprint (Under review) </font> </em>, 2024 </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2402.16227" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=yrDwPwg4WFI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>This paper presents a novel distributed robust optimization scheme for steering distributions of multi-agent systems under stochastic and deterministic uncertainty. Robust optimization is a subfield of optimization which aims in discovering an optimal solution that remains robustly feasible for all possible realizations of the problem parameters within a given uncertainty set. Such approaches would naturally constitute an ideal candidate for multi-robot control, where in addition to stochastic noise, there might be exogenous deterministic disturbances. Nevertheless, as these methods are usually associated with significantly high computational demands, their application to multi-agent robotics has remained limited. The scope of this work is to propose a scalable robust optimization framework that effectively addresses both types of uncertainties, while retaining computational efficiency and scalability. In this direction, we provide tractable approximations for robust constraints that relevant in multi-robot settings. Subsequently, we demonstrate how computations can be distributed through an Alternating Direction Method of Multipliers (ADMM) approach towards achieving scalability and communication efficiency. Simulation results highlight the performance of the proposed algorithm in effectively handling both stochastic and deterministic uncertainty in multi-robot systems. The scalability of the method is also emphasized by showcasing tasks with up to 100 agents. The results of this work indicate the promise of blending robust optimization, distribution steering and distributed optimization towards achieving scalable, safe and robust multi-robot control.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IROS 2024 </abbr></div> 
<div id="saravanos2022distributed_mpcs" class="col-sm-8"> 
<div class="title"> <font size="+1">Distributed Model Predictive Covariance Steering</font> </div> 
<div class="author"> <strong> <font color="#3B57D3"> A.D. Saravanos</font> </strong>, I.M. Balci, E. Bakolas, and E.A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) </font> </em>, 2024 </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2212.00398" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=Hks-0BRozxA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>This paper proposes Distributed Model Predictive Covariance Steering (DMPCS), a novel method for safe multi-robot control under uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single methodology that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-robot team to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers (ADMM). This method is then extended to a receding horizon form, which yields the proposed DMPCS algorithm. Simulation experiments on large-scale problems with up to hundreds of robots successfully demonstrate the effectiveness and scalability of DMPCS. Its superior capability in achieving safety is also highlighted through a comparison against a standard stochastic MPC approach.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IEEE Transactions <br> on Robotics </abbr></div> 
<div id="saravanos2022distributed_ddp" class="col-sm-8"> 
<div class="title"> <font size="+1">Distributed Differential Dynamic Programming Architectures for Large-Scale Multi-Agent Control</font> </div> 
<div class="author"> <strong> <font color="#3B57D3"> A.D. Saravanos</font> </strong>, Y. Aoyama, H. Zhu, and E. A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393">IEEE Transactions on Robotics </font> </em>, 2023. <font color="#911d09"> [Acceptance rate: ~18%] </font> </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2207.13255" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=tluvENcWldw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>In this paper, we propose two novel decentralized optimization frameworks for multi-agent nonlinear optimal control problems in robotics. The aim of this work is to suggest architectures that inherit the computational efficiency and scalability of Differential Dynamic Programming (DDP) and the distributed nature of the Alternating Direction Method of Multipliers (ADMM). In this direction, two frameworks are introduced. The first one called Nested Distributed DDP (ND-DDP), is a three-level architecture which employs ADMM for enforcing a consensus between all agents, an Augmented Lagrangian layer for satisfying local constraints and DDP as each agent’s optimizer. In the second approach, both consensus and local constraints are handled with ADMM, yielding a two-level architecture called Merged Distributed DDP (MD-DDP), which further reduces computational complexity. Both frameworks are fully decentralized since all computations are parallelizable among the agents and only local communication is necessary. Simulation results that scale up to thousands of vehicles and hundreds of drones verify the effectiveness of the methods. Superior scalability to large-scale systems against centralized DDP and centralized/decentralized sequential quadratic programming is also illustrated. Finally, hardware experiments on a multi-robot platform demonstrate the applicability of the proposed algorithms, while highlighting the importance of optimizing for feedback policies to increase robustness against uncertainty. <a href="https://youtu.be/tluvENcWldw" target="_blank" rel="noopener noreferrer">A video with all results is available here</a>.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2023 </abbr></div> 
<div id="saravanos2023hierarchical" class="col-sm-8"> 
<div class="title"> <font size="+1">Distributed Hierarchical Distribution Control for Very-Large-Scale Clustered Multi-Agent Systems</font> </div> 
<div class="author"> <strong> <font color="#3B57D3"> A.D. Saravanos</font> </strong>, Y. Li and E.A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393">Robotics: Science and Systems</font> </em>, 2023. <font color="#911d09"> [Acceptance rate: 33.6%] </font> </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.roboticsproceedings.org/rss18/p055.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=0QPyR4bD2q0" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>As the scale and complexity of multi-agent robotic systems are subject to a continuous increase, this paper considers a class of systems labeled as Very-Large-Scale Multi-Agent Systems (VLMAS) with dimensionality that can scale up to the order of millions of agents. In particular, we consider the problem of steering the state distributions of all agents of a VLMAS to prescribed target distributions while satisfying probabilistic safety guarantees. Based on the key assumption that such systems often admit a multi-level hierarchical clustered structure - where the agents are organized into cliques of different levels -  we associate the control of such cliques with the control of distributions, and introduce the Distributed Hierarchical Distribution Control (DHDC) framework. The proposed approach consists of two sub-frameworks. The first one, Distributed Hierarchical Distribution Estimation (DHDE), is a bottom-up hierarchical decentralized algorithm which links the initial and target configurations of the cliques of all levels with suitable Gaussian distributions. The second part, Distributed Hierarchical Distribution Steering (DHDS), is a top-down hierarchical distributed method that steers the distributions of all cliques and agents from the initial to the targets ones assigned by DHDE. Simulation results that scale up to two million agents demonstrate the effectiveness and scalability of the proposed framework. The increased computational efficiency and safety performance of DHDC against related methods is also illustrated. The results of this work indicate the importance of hierarchical distribution control approaches towards achieving safe and scalable solutions for the control of VLMAS.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2022 </abbr></div> 
<div id="pereira2022decentralized" class="col-sm-8"> <div class="title"> <font size="+1">Decentralized Safe Multi-agent Stochastic Optimal Control using Deep FBSDEs and ADMM</font> </div> 
<div class="author"> M.A. Pereira*, <strong> <font color="#3B57D3"> A.D. Saravanos*</font> </strong>, O. So, and E.A. Theodorou</div> 
<div class="periodical"> <em> <font color="#104393">Robotics: Science and Systems </font> </em>, 2022. <font color="#911d09"> [Acceptance rate: 31.8%] </font> </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.roboticsproceedings.org/rss18/p055.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=qjPLUlaxJos" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>In this work, we propose a novel safe and scalable decentralized solution for multi-agent control in the presence of stochastic. Safety is mathematically encoded using stochastic control barrier functions and safe controls are computed by solving quadratic programs. Decentralization is achieved by augmenting to each agent’s optimization variables, copy variables, for its neighboring agents. This allows us to decouple the centralized multi-agent optimization problem. However, to ensure safety, neighboring agents must agree on what is safe for both of us and this creates a need for consensus. To enable safe consensus solutions, we incorporate an ADMM-based approach. Specifically, we propose a Merged CADMM-OSQP implicit neural network layer, that solves a mini-batch of both, local quadratic programs as well as the overall consensus problem, as a single optimization problem. This layer is embedded within a Deep FBSDEs network architecture at every time step, to facilitate end-to-end differentiable, safe and decentralized stochastic optimal control. The efficacy of the proposed approach is demonstrated on several challenging multi-robot tasks in simulation. By imposing requirements on safety specified by collision avoidance constraints, the safe operation of all agents is ensured during the entire training process. We also demonstrate superior scalability in terms of computational and memory savings as compared to a centralized approach.</p> </div> 
</div> 
</div> 
</li> 

<li> 
<div class="row"> 
<div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2021 </abbr></div> 
<div id="saravanos2021distributed" class="col-sm-8"> 
<div class="title"> <font size="+1">Distributed Covariance Steering with Consensus ADMM for Stochastic Multi-Agent Systems</font> </div> 
<div class="author"> <strong> <font color="#3B57D3"> A.D. Saravanos</font> </strong>, A. Tsolovikos, E. Bakolas, and E.A. Theodorou</div> 
<div class="periodical"> <em><font color="#104393"> Robotics: Science and Systems</font> </em> , 2021. <font color="#911d09"> [Acceptance rate: 32.6%] </font> </div> 
<div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.roboticsproceedings.org/rss17/p075.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=RiLQ2P1WXHQ" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> 
<div class="abstract hidden"> <p>In this paper, we address the problem of steering a team of agents under stochastic linear dynamics to prescribed final state means and covariances. The agents operate in a common environment where inter-agent constraints may also be present. In order for our method to be scalable to large-scale systems and computationally efficient, we approach the problem in a distributed control framework using the Alternating Direction Method of Multipliers (ADMM). Each agent solves its own covariance steering problem in parallel, while additional copy variables for its closest neighbors are introduced to ensure that the inter-agent constraints will be satisfied. The inclusion of these additional variables creates a requirement for consensus between original and copy variables that involve the same agent. For this reason, we employ a variation of ADMM for consensus optimization. Simulation results on multi-vehicle systems under uncertainty with collision avoidance constraints illustrate the effectiveness of our algorithm. The substantially improved scalability of our distributed approach with respect to the number of agents is also demonstrated, in comparison with an equivalent centralized scheme.</p> </div> 
</div> 
</div> 
</li>

</ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Augustinos (Augustine) Saravanos. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
