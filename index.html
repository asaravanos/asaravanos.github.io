<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Augustinos Saravanos</title>
    <meta name="author" content="Augustinos Saravanos"/>
    <meta name="description"
          content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/>
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css"
          integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"
          integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"
          integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css"
          href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media=""
          id="highlight_theme_light"/>
    <link rel="shortcut icon"
          href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://asaravanos.github.io/">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css"
          media="none" id="highlight_theme_dark"/>
    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
</head>
<body class="fixed-top-nav ">
<header>
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
            <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse"
                    data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false"
                    aria-label="Toggle navigation"><span class="sr-only">Toggle navigation</span> <span
                    class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span
                    class="icon-bar bottom-bar"></span></button>
            <div class="collapse navbar-collapse text-right" id="navbarNav">
                <ul class="navbar-nav ml-auto flex-nowrap">
                    <li class="nav-item active"><a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
                    </li>
                    <li class="nav-item"><a class="nav-link"
                                            href="https://asaravanos.github.io/assets/pdf/Saravanos_CV.pdf"
                                            target="\_blank">CV</a></li>
                    <li class="nav-item">
                        <a class="nav-link" href="publications.html" target="_self">Publications</a>
                    </li>
                    <li class="toggle-container">
                        <button id="light-toggle" title="Change theme"><i class="fas fa-moon"></i> <i
                                class="fas fa-sun"></i></button>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <progress id="progress" value="0">
        <div class="progress-container"><span class="progress-bar"></span></div>
    </progress>
</header>
<div class="container mt-5">
    <div class="post">
        <header class="post-header"><h1 class="post-title"><span class="font-weight-bold">Augustinos </span> Saravanos
        </h1>
            <h5><strong>Postdoc @ MIT</strong> </h5></header>
        <article>
            <div class="profile float-right">
                <figure>
                    <picture><img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto"
                                  height="auto" alt="prof_pic.jpg"
                                  onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></picture>
                </figure>
            </div>
            <div class="clearfix">
            <p>
                Hi, I’m a <strong>postdoctoral associate</strong> at <strong>MIT AeroAstro</strong>, working at the
                <a href="https://aeroastro.mit.edu/realm/" target="_blank" rel="noopener noreferrer">REALM Lab</a>
                with Prof. <a href="https://chuchu.mit.edu/" target="_blank" rel="noopener noreferrer">Chuchu Fan</a>.
                I received my <strong>PhD in Machine Learning</strong> at <strong>Georgia Tech</strong> in 2025, where I was advised by
                Prof. <a href="https://scholar.google.com/citations?hl=en&user=dG9MV7oAAAAJ" target="_blank" rel="noopener noreferrer">Evangelos Theodorou</a>.
                During my PhD, I was also honored to be an
                <a href="https://www.onassis.org/initiatives/scholarships" target="_blank" rel="noopener noreferrer">Onassis Foundation Scholar</a>
                from 2021 to 2025.
                I also hold a <strong>M.Sc. in Aerospace Engineering</strong> from <strong>Georgia Tech</strong>, as well as a
                <strong>Diploma in Electrical and Computer Engineering</strong> (top 1%) from the
                <strong>University of Patras</strong> in Greece.
            </p>

            <p>
                My research bridges <strong>optimization</strong>, <strong>machine learning</strong>, and <strong>control theory</strong>
                towards developing <strong>scalable</strong>, <strong>robust</strong>, and <strong>generalizable</strong> methods for
                <strong>large-scale decision-making</strong> systems in autonomy, transportation, resource allocation, and many other
                application areas.
            </p>

            <p>
                See my <strong><a href="https://asaravanos.github.io/assets/pdf/Saravanos_CV.pdf" target="_blank">full CV</a></strong> here.
            </p>

            <p>
                <strong>Contact:</strong> <a href="mailto:asaravan@mit.edu">asaravan [at] mit [dot] edu</a>
            </p>
            </div>

            <div class="post" style="max-width: 100vw; width: 100%;">
            <h3 id="post">News</h3>

            <table style="border-collapse: collapse; width: 100%; line-height: 1.6;">
                <tbody>
                <tr>
                    <td style="white-space: nowrap; vertical-align: top; padding-right: 0.3em;">Sep 2025</td>
                    <td>Our paper
                    <strong><a href="https://arxiv.org/abs/2506.10168" target="_blank">
                    Momentum Multi-Marginal Schrödinger Bridge Matching</a></strong>
                    is accepted at <strong>NeurIPS 2025</strong>.
                    </td>
                </tr>

                <tr>
                    <td style="white-space: nowrap; vertical-align: top; padding-right: 0.3em;">Sep 2025</td>
                    <td>Our paper
                    <strong><a href="https://arxiv.org/abs/2508.11799" target="_blank">
                    Scaling Robust Optimization for Swarms: A Distributed Perspective</a></strong>
                    available on arXiv.
                    </td>
                </tr>

                <tr>
                    <td style="white-space: nowrap; vertical-align: top; padding-right: 0.3em;">Aug 2025</td>
                    <td>I have joined <strong>MIT</strong> as a <strong>postdoc</strong>! I’ll be working 
                with Prof. <a href="https://chuchu.mit.edu/" target="_blank" rel="noopener noreferrer">Chuchu Fan</a> at the <a href="https://aeroastro.mit.edu/realm/" target="_blank" rel="noopener noreferrer">REALM Lab</a>.
                    </td>
                </tr>

                <tr>
                    <td style="white-space: nowrap; vertical-align: top; padding-right: 0.3em;">Jul 2025</td>
                    <td>I defended my <strong>PhD thesis</strong> on
                    <strong><a href="https://repository.gatech.edu/entities/publication/ea27339d-e8cb-42d1-9180-571c809242bd" target="_blank" rel="noopener noreferrer">Distributed Optimization Architectures for Large-Scale Decision-Making</a></strong> at <strong>Georgia Tech</strong>! 
                    Many thanks to my advisor Prof. <a href="https://scholar.google.com/citations?hl=en&user=dG9MV7oAAAAJ" target="_blank" rel="noopener noreferrer">Evangelos Theodorou</a> and my committee Profs. 
                    <a href="https://www.isye.gatech.edu/users/arkadi-nemirovski" target="_blank" rel="noopener noreferrer">Arkadi Nemirovski</a>, 
                    <a href="https://www2.isye.gatech.edu/~yxie77/" target="_blank" rel="noopener noreferrer">Yao Xie</a>, 
                    <a href="https://ece.gatech.edu/directory/justin-romberg" target="_blank" rel="noopener noreferrer">Justin Romberg</a>, and 
                    <a href="https://www.ae.utexas.edu/people/faculty/faculty-directory/bakolas" target="_blank" rel="noopener noreferrer">Efstathios Bakolas</a>.
                    </td>
                </tr>

                <tr>
                    <td style="white-space: nowrap; vertical-align: top; padding-right: 0.3em;">Jul 2025</td>
                    <td>Our papers <strong><a href="https://arxiv.org/abs/2504.04605" target="_blank">Nonlinear Robust Optimization for Planning and Control</a></strong> and 
                    <strong><a href="https://arxiv.org/abs/2411.11211" target="_blank">Operator Splitting Covariance Steering for Safe Stochastic Nonlinear Control</a></strong> have been accepted at <strong>CDC 2025</strong>.</td>
                </tr>
                </tbody>
            </table>
            </div>

            <div class="publications" style="max-width: 100vw; width: 100%;">
                <h3 id="selected-publications">Selected Publications</h3>
                <p class="intro-text">
                    * Equal contribution. See <a href="https://scholar.google.com/citations?user=6XP9s1MAAAAJ&hl=en">Google
                    Scholar</a> for full list of publications.
                </p>
                <ol class="bibliography">

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div>
                            <div id="saravanos2024deep">
                                <div class="title"><font size="+1">Deep Distributed Optimization for Large-Scale
                                    Quadratic Programming</font></div>
                                <div class="author"><strong><font color="#0056b3"> A.D. Saravanos</font></strong>, H.
                                    Kuperman, A. Oshin, A.T. Abdul, V. Pacelli and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700"> International Conference on Learning Representations (ICLR)</font></strong>, 2025.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://openreview.net/pdf?id=hzuumhfYSO" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a></div>
                                <div class="abstract hidden"><p>Quadratic programming (QP) forms a crucial foundation in
                                    optimization, encompassing a broad spectrum of domains and serving as the basis for
                                    more advanced algorithms. Consequently, as the scale and complexity of modern
                                    applications continue to grow, the development of efficient and reliable QP
                                    algorithms is becoming increasingly vital. In this context, this paper introduces a
                                    novel deep learning-aided distributed optimization architecture designed for
                                    tackling large-scale QP problems. First, we combine the state-of-the-art Operator
                                    Splitting QP (OSQP) method with a consensus approach to derive DistributedQP, a new
                                    method tailored for network-structured problems, with convergence guarantees to
                                    optimality. Subsequently, we unfold this optimizer into a deep learning framework,
                                    leading to DeepDistributedQP, which leverages learned policies to accelerate
                                    reaching to desired accuracy within a restricted amount of iterations. Our approach
                                    is also theoretically grounded through Probably Approximately Correct (PAC)-Bayes
                                    theory, providing generalization bounds on the expected optimality gap for unseen
                                    problems. The proposed framework, as well as its centralized version DeepQP,
                                    significantly outperform their standard optimization counterparts on a variety of
                                    tasks such as randomly generated problems, optimal control, linear regression,
                                    transportation networks and others. Notably, DeepDistributedQP demonstrates strong
                                    generalization by training on small problems and scaling to solve much larger ones
                                    (up to 50K variables and 150K constraints) using the same policy. Moreover, it
                                    achieves orders-of-magnitude improvements in wall-clock time compared to OSQP. The
                                    certifiable performance guarantees of our approach are also demonstrated, ensuring
                                    higher-quality solutions over traditional optimizers.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div>
                            <div id="saravanos2024deep">
                                <div class="title"><font size="+1">Second-Order Constrained Dynamic Optimization</font></div>
                                <div class="author">Y. Aoyama, O. So, <strong><font color="#0056b3"> A.D. Saravanos</font></strong> and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700">International Journal of Robotics Research (IJRR)</font></strong>  <font color="#b34700"> - Under minor revision</font>, 2025.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://arxiv.org/pdf/2409.11649" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a></div>
                                <div class="abstract hidden"><p>This paper provides an overview, analysis, and comparison of second-order dynamic optimization algorithms, i.e., constrained Differential 
                                    Dynamic Programming (DDP) and Sequential Quadratic Programming (SQP). Although a variety of these algorithms have been proposed and used successfully, there exists a 
                                    gap in understanding the key differences and advantages, which we aim to provide in this work. For constrained DDP, we choose methods that incorporate nonlinear 
                                    programming techniques to handle state and control constraints, including Augmented Lagrangian (AL), Interior Point, Primal-Dual Augmented Lagrangian (PDAL), and 
                                    Alternating Direction Method of Multipliers (ADMM). Both DDP and SQP are provided in single- and multiple-shooting formulations, where constraints that arise from dynamics 
                                    are encoded implicitly and explicitly, respectively. As a byproduct of the review, we propose a single-shooting PDAL DDP that has more favorable properties than the 
                                    standard AL variant, such as the robustness to the growth of penalty parameters. We perform extensive numerical experiments on a variety of systems with increasing 
                                    complexity to investigate the quality of the solutions, the levels of constraint violation, and the sensitivity of final solutions with respect to initialization, as well 
                                    as targets. The results show that single-shooting PDAL DDP and multiple-shooting SQP are the most robust methods. For multiple-shooting formulation, both DDP and SQP can 
                                    enjoy informed initial guesses, while the latter appears to be more advantageous in complex systems. It is also worth highlighting that DDP provides favorable computational 
                                    complexity and feedback gains as a byproduct of optimization as is.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div>
                            <div id="saravanos2024deep">
                                <div class="title"><font size="+1">Momentum Multi-Marginal Schrödinger Bridge Matching</font></div>
                                <div class="author">P. Theodoropoulos, <strong><font color="#0056b3"> A.D. Saravanos</font></strong>, E.A. Theodorou and G.H. Liu
                                </div>
                                <div class="periodical"> <strong><font color="#b34700"> Neural Information Processing Systems (NeurIPS)</font></strong>, 2025.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://arxiv.org/pdf/2506.10168" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a></div>
                                <div class="abstract hidden"><p>Understanding complex systems by inferring trajectories from sparse sample snapshots is a fundamental challenge in a wide range of domains, 
                                    e.g., single-cell biology, meteorology, and economics. Despite advancements in Bridge and Flow matching frameworks, current methodologies rely on pairwise interpolation 
                                    between adjacent snapshots. This hinders their ability to capture long-range temporal dependencies and potentially affects the coherence of the inferred trajectories. 
                                    To address these issues, we introduce \textbf{Momentum Multi-Marginal Schr\"odinger Bridge Matching (3MSBM)}, a novel matching framework that learns smooth measure-valued 
                                    splines for stochastic systems that satisfy multiple positional constraints. This is achieved by lifting the dynamics to phase space and generalizing stochastic bridges 
                                    to be conditioned on several points, forming a multi-marginal conditional stochastic optimal control problem. The underlying dynamics are then learned by minimizing a 
                                    variational objective, having fixed the path induced by the multi-marginal conditional bridge. As a matching approach, 3MSBM learns transport maps that preserve intermediate 
                                    marginals throughout training, significantly improving convergence and scalability. Extensive experimentation in a series of real-world applications validates the superior 
                                    performance of 3MSBM compared to existing methods in capturing complex dynamics with temporal dependencies, opening new avenues for training matching frameworks in multi-marginal settings.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;"> Preprint </abbr></div>
                            <div id="abdul2024robust">
                                <div class="title"><font size="+1">Scaling Robust Optimization for Swarms: A Distributed Perspective</font></div>
                                <div class="author"> A.T. Abdul*, <strong><font color="#0056b3"> A.D. Saravanos*</font></strong> and E.A. Theodorou
                                </div>
                                <div class="periodical"><strong><font color="#b34700">IEEE Transactions on Automatic Control (TAC)</font></strong>  <font color="#b34700"> - Under review</font>, 2025.
                                </div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://arxiv.org/pdf/2508.11799" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a
                                            href="https://youtu.be/Q5xghaqt4SQ"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>This article introduces a decentralized robust optimization framework for safe multi-agent control under uncertainty. Although stochastic noise 
                                    has been the primary form of modeling uncertainty in such systems, these formulations might fall short in addressing uncertainties that are deterministic in nature or simply 
                                    lack probabilistic data. To ensure safety under such scenarios, we employ the concept of robust constraints that must hold for all possible uncertainty realizations lying 
                                    inside a bounded set. Nevertheless, standard robust optimization approaches become intractable due to the large number or non-convexity of the constraints involved in safe 
                                    multi-agent control. To address this, we introduce novel robust reformulations that significantly reduce complexity without compromising safety. The applicability of the 
                                    framework is further broadened to address both deterministic and stochastic uncertainties by incorporating robust chance constraints and distribution steering techniques. 
                                    To achieve scalability, we derive a distributed approach based on the Alternating Direction Method of Multipliers (ADMM), supported by a convergence study that accounts for 
                                    the underlying non-convexity. In addition, computational complexity bounds highlighting the efficiency of the proposed frameworks against standard approaches are presented. 
                                    Finally, the robustness and scalability of the framework is demonstrated through extensive simulation results across diverse scenarios, including environments with nonconvex 
                                    obstacles and up to 246 agents.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IROS 2024 </abbr></div>
                            <div id="saravanos2022distributed_mpcs">
                                <div class="title"><font size="+1">Distributed Model Predictive Covariance
                                    Steering</font></div>
                                <div class="author"><strong><font color="#0056b3"> A.D. Saravanos</font></strong>, I.M.
                                    Balci, E. Bakolas, and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700">IEEE/RSJ International Conference on
                                    Intelligent Robots and Systems (IROS)</font></strong>, 2024.
                                </div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://arxiv.org/abs/2212.00398" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a
                                            href="https://youtu.be/tzWqOzuj2kQ"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>This paper proposes Distributed Model Predictive Covariance Steering (DiMPCS) for multi-agent control under stochastic uncertainty. 
                                    The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single framework that is safe, 
                                    scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-agent system to 
                                    desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance 
                                    feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized 
                                    consensus-based algorithm using the Alternating Direction Method of Multipliers. This method is then extended to a receding horizon form, which yields the proposed 
                                    DiMPCS algorithm. Simulation experiments on a variety of multi-robot tasks with up to hundreds of robots demonstrate the effectiveness of DiMPCS. The superior scalability 
                                    and performance of the proposed method is also highlighted through a comparison against related stochastic MPC approaches. Finally, hardware results on a multi-robot 
                                    platform also verify the applicability of DiMPCS on real systems.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IEEE Transactions <br>
                                on Robotics </abbr></div>
                            <div id="saravanos2022distributed_ddp">
                                <div class="title"><font size="+1">Distributed Differential Dynamic Programming
                                    Architectures for Large-Scale Multi-Agent Control</font></div>
                                <div class="author"><strong><font color="#0056b3"> A.D. Saravanos</font></strong>, Y.
                                    Aoyama, H. Zhu, and E. A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700">IEEE Transactions on Robotics (T-RO)</font></strong>, 2023.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://arxiv.org/abs/2207.13255" class="btn btn-sm z-depth-0"
                                       role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a
                                            href="https://www.youtube.com/watch?v=tluvENcWldw"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>In this paper, we propose two novel decentralized
                                    optimization frameworks for multi-agent nonlinear optimal control problems in
                                    robotics. The aim of this work is to suggest architectures that inherit the
                                    computational efficiency and scalability of Differential Dynamic Programming (DDP)
                                    and the distributed nature of the Alternating Direction Method of Multipliers
                                    (ADMM). In this direction, two frameworks are introduced. The first one called
                                    Nested Distributed DDP (ND-DDP), is a three-level architecture which employs ADMM
                                    for enforcing a consensus between all agents, an Augmented Lagrangian layer for
                                    satisfying local constraints and DDP as each agent’s optimizer. In the second
                                    approach, both consensus and local constraints are handled with ADMM, yielding a
                                    two-level architecture called Merged Distributed DDP (MD-DDP), which further reduces
                                    computational complexity. Both frameworks are fully decentralized since all
                                    computations are parallelizable among the agents and only local communication is
                                    necessary. Simulation results that scale up to thousands of vehicles and hundreds of
                                    drones verify the effectiveness of the methods. Superior scalability to large-scale
                                    systems against centralized DDP and centralized/decentralized sequential quadratic
                                    programming is also illustrated. Finally, hardware experiments on a multi-robot
                                    platform demonstrate the applicability of the proposed algorithms, while
                                    highlighting the importance of optimizing for feedback policies to increase
                                    robustness against uncertainty. <a href="https://youtu.be/tluvENcWldw"
                                                                       target="_blank" rel="noopener noreferrer">A video
                                        with all results is available here</a>.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2023 </abbr></div>
                            <div id="saravanos2023hierarchical">
                                <div class="title"><font size="+1">Distributed Hierarchical Distribution Control for
                                    Very-Large-Scale Clustered Multi-Agent Systems</font></div>
                                <div class="author"><strong><font color="#0056b3"> A.D. Saravanos</font></strong>, Y.
                                    Li and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700">Robotics: Science and Systems (RSS)</font></strong>, 2023.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="https://www.roboticsproceedings.org/rss19/p110.html"
                                       class="btn btn-sm z-depth-0" role="button" target="_blank"
                                       rel="noopener noreferrer">PDF</a> <a
                                            href="https://www.youtube.com/watch?v=0QPyR4bD2q0"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>As the scale and complexity of multi-agent robotic
                                    systems are subject to a continuous increase, this paper considers a class of
                                    systems labeled as Very-Large-Scale Multi-Agent Systems (VLMAS) with dimensionality
                                    that can scale up to the order of millions of agents. In particular, we consider the
                                    problem of steering the state distributions of all agents of a VLMAS to prescribed
                                    target distributions while satisfying probabilistic safety guarantees. Based on the
                                    key assumption that such systems often admit a multi-level hierarchical clustered
                                    structure - where the agents are organized into cliques of different levels - we
                                    associate the control of such cliques with the control of distributions, and
                                    introduce the Distributed Hierarchical Distribution Control (DHDC) framework. The
                                    proposed approach consists of two sub-frameworks. The first one, Distributed
                                    Hierarchical Distribution Estimation (DHDE), is a bottom-up hierarchical
                                    decentralized algorithm which links the initial and target configurations of the
                                    cliques of all levels with suitable Gaussian distributions. The second part,
                                    Distributed Hierarchical Distribution Steering (DHDS), is a top-down hierarchical
                                    distributed method that steers the distributions of all cliques and agents from the
                                    initial to the targets ones assigned by DHDE. Simulation results that scale up to
                                    two million agents demonstrate the effectiveness and scalability of the proposed
                                    framework. The increased computational efficiency and safety performance of DHDC
                                    against related methods is also illustrated. The results of this work indicate the
                                    importance of hierarchical distribution control approaches towards achieving safe
                                    and scalable solutions for the control of VLMAS.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2022 </abbr></div>
                            <div id="pereira2022decentralized">
                                <div class="title"><font size="+1">Decentralized Safe Multi-agent Stochastic Optimal
                                    Control using Deep FBSDEs and ADMM</font></div>
                                <div class="author"> M.A. Pereira*, <strong><font color="#0056b3"> A.D. Saravanos*</font></strong>, O. So, and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700">Robotics: Science and Systems (RSS)</font></strong>, 2022. </div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="http://www.roboticsproceedings.org/rss18/p055.html"
                                       class="btn btn-sm z-depth-0" role="button" target="_blank"
                                       rel="noopener noreferrer">PDF</a> <a
                                            href="https://www.youtube.com/watch?v=qjPLUlaxJos"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>In this work, we propose a novel safe and scalable
                                    decentralized solution for multi-agent control in the presence of stochastic. Safety
                                    is mathematically encoded using stochastic control barrier functions and safe
                                    controls are computed by solving quadratic programs. Decentralization is achieved by
                                    augmenting to each agent’s optimization variables, copy variables, for its
                                    neighboring agents. This allows us to decouple the centralized multi-agent
                                    optimization problem. However, to ensure safety, neighboring agents must agree on
                                    what is safe for both of us and this creates a need for consensus. To enable safe
                                    consensus solutions, we incorporate an ADMM-based approach. Specifically, we propose
                                    a Merged CADMM-OSQP implicit neural network layer, that solves a mini-batch of both,
                                    local quadratic programs as well as the overall consensus problem, as a single
                                    optimization problem. This layer is embedded within a Deep FBSDEs network
                                    architecture at every time step, to facilitate end-to-end differentiable, safe and
                                    decentralized stochastic optimal control. The efficacy of the proposed approach is
                                    demonstrated on several challenging multi-robot tasks in simulation. By imposing
                                    requirements on safety specified by collision avoidance constraints, the safe
                                    operation of all agents is ensured during the entire training process. We also
                                    demonstrate superior scalability in terms of computational and memory savings as
                                    compared to a centralized approach.</p></div>
                            </div>
                        </div>
                    </li>

                    <li>
                        <div>
                            <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">RSS 2021 </abbr></div>
                            <div id="saravanos2021distributed">
                                <div class="title"><font size="+1">Distributed Covariance Steering with Consensus ADMM
                                    for Stochastic Multi-Agent Systems</font></div>
                                <div class="author"><strong><font color="#0056b3"> A.D. Saravanos</font></strong>, A.
                                    Tsolovikos, E. Bakolas, and E.A. Theodorou
                                </div>
                                <div class="periodical"> <strong><font color="#b34700"> Robotics: Science and Systems (RSS)</font></strong>, 2021.</div>
                                <div class="links"><a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                    <a href="http://www.roboticsproceedings.org/rss17/p075.html"
                                       class="btn btn-sm z-depth-0" role="button" target="_blank"
                                       rel="noopener noreferrer">PDF</a> <a
                                            href="https://www.youtube.com/watch?v=RiLQ2P1WXHQ"
                                            class="btn btn-sm z-depth-0" role="button" target="_blank"
                                            rel="noopener noreferrer">Video</a></div>
                                <div class="abstract hidden"><p>In this paper, we address the problem of steering a team
                                    of agents under stochastic linear dynamics to prescribed final state means and
                                    covariances. The agents operate in a common environment where inter-agent
                                    constraints may also be present. In order for our method to be scalable to
                                    large-scale systems and computationally efficient, we approach the problem in a
                                    distributed control framework using the Alternating Direction Method of Multipliers
                                    (ADMM). Each agent solves its own covariance steering problem in parallel, while
                                    additional copy variables for its closest neighbors are introduced to ensure that
                                    the inter-agent constraints will be satisfied. The inclusion of these additional
                                    variables creates a requirement for consensus between original and copy variables
                                    that involve the same agent. For this reason, we employ a variation of ADMM for
                                    consensus optimization. Simulation results on multi-vehicle systems under
                                    uncertainty with collision avoidance constraints illustrate the effectiveness of our
                                    algorithm. The substantially improved scalability of our distributed approach with
                                    respect to the number of agents is also demonstrated, in comparison with an
                                    equivalent centralized scheme.</p></div>
                            </div>
                        </div>
                    </li>

                </ol>
            </div>
        </article>
    </div>
</div>
<footer class="fixed-bottom">
    <div class="container mt-0"> © Copyright 2024 Augustinos (Augustine) Saravanos. Powered by <a
            href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a
            href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
        Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos
        from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.
    </div>
</footer>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"
        integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js"
        integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js"
        integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/masonry.js" type="text/javascript"></script>
<script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"
        integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script defer src="/assets/js/zoom.js"></script>
<script defer src="/assets/js/common.js"></script>
<script type="text/javascript">window.MathJax = {tex: {tags: "ams"}};</script>
<script defer type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript">function progressBarSetup() {
    "max" in document.createElement("progress") ? (initializeProgressElement(), $(document).on("scroll", function () {
        progressBar.attr({value: getCurrentScrollPosition()})
    }), $(window).on("resize", initializeProgressElement)) : (resizeProgressBar(), $(document).on("scroll", resizeProgressBar), $(window).on("resize", resizeProgressBar))
}

function getCurrentScrollPosition() {
    return $(window).scrollTop()
}

function initializeProgressElement() {
    let e = $("#navbar").outerHeight(!0);
    $("body").css({"padding-top": e}), $("progress-container").css({"padding-top": e}), progressBar.css({top: e}), progressBar.attr({
        max: getDistanceToScroll(),
        value: getCurrentScrollPosition()
    })
}

function getDistanceToScroll() {
    return $(document).height() - $(window).height()
}

function resizeProgressBar() {
    progressBar.css({width: getWidthPercentage() + "%"})
}

function getWidthPercentage() {
    return getCurrentScrollPosition() / getDistanceToScroll() * 100
}

const progressBar = $("#progress");
window.onload = function () {
    setTimeout(progressBarSetup, 50)
};</script>
</body>
</html>
