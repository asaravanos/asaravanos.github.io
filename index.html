<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Augustinos Saravanos</title> <meta name="author" content="Augustinos (Augustine) Saravanos"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://asaravanos.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item"> <a class="nav-link" href="https://asaravanos.github.io/assets/pdf/Augustinos_CV_Dec24.pdf" target="\_blank">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Augustinos</span> (Augustine) Saravanos </h1> <p class="desc">PhD in Machine Learning Student @ <a href="https://sites.gatech.edu/acds/" target="_blank" rel="noopener noreferrer"> ACDS Lab </a>, Georgia Tech</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I’m a third year PhD in Machine Learning student at Georgia Tech. I am fortunate to be part of the <a href="https://sites.gatech.edu/acds/" target="_blank" rel="noopener noreferrer"> Autonomous Control and Decision Systems Lab </a> and to be advised by <a href="https://ae.gatech.edu/people/evangelos-theodorou" target="_blank" rel="noopener noreferrer"> Prof. Evangelos Theodorou</a>. I also work closely with <a href="https://www.ae.utexas.edu/people/faculty/faculty-directory/bakolas" target="_blank" rel="noopener noreferrer"> Prof. Efstathios Bakolas</a> from UT Austin.</p> <p>My research focuses on developing <b> distributed methods </b> for the control of <b> large-scale multi-agent systems </b>. In particular, combining concepts from the areas of distributed optimization, stochastic optimal control and machine learning, my work aims in developing scalable and computationally efficient decentralized algorithms for controlling multi-agent systems with thousands of robots!</p> <p>Some indicative works are <b> <font color="#3EBC34">Distributed Differential Dynamic Programming</font> </b> <a href="https://arxiv.org/abs/2207.13255" target="_blank" rel="noopener noreferrer">[Paper (preprint)</a>, <a href="https://www.youtube.com/watch?v=tluvENcWldw" target="_blank" rel="noopener noreferrer"> Video]</a>, <b> <font color="#B91BDC"> Decentralized Multi-Agent Deep FBSDEs </font> </b> <a href="http://www.roboticsproceedings.org/rss18/p055.html" target="_blank" rel="noopener noreferrer">[Paper (RSS ‘22)</a>, <a href="https://www.youtube.com/watch?v=qjPLUlaxJos" target="_blank" rel="noopener noreferrer"> Video]</a> and <b> <font color="#D16124"> Distributed Covariance Steering </font> </b> <a href="http://www.roboticsproceedings.org/rss17/p075.html" target="_blank" rel="noopener noreferrer"> [Paper (RSS ‘21) </a>, <a href="https://www.youtube.com/watch?v=RiLQ2P1WXHQ" target="_blank" rel="noopener noreferrer"> Video]</a>.</p> <p>Prior to Georgia Tech, I graduated (top 1%) with a Diploma in Electrical and Computer Engineering from the University of Patras in Greece, and was advised by <a href="https://nereus.mech.ntua.gr/" target="_blank" rel="noopener noreferrer"> Prof. Evangelos Papadopoulos</a> and <a href="http://www.ece.upatras.gr/index.php/en/ece-faculty/koussoulas-nick.html" target="_blank" rel="noopener noreferrer"> Prof. Nick Koussoulas</a>.</p> <p>See my <b> <a href="https://asaravanos.github.io/assets/pdf/Augustinos_CV_Dec24.pdf" target="_blank">full CV</a> </b> here.</p> <p><b> 
Contact: </b> <a href="mailto:asaravanos3@gatech.edu">asaravanos3 [at] gatech [dot] edu</a></p> </div> 

<div class="publications"> <h2>Selected Publications</h2> <ol class="bibliography"> 
    
<li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IROS 2024 </abbr></div> <div id="saravanos2022distributed_mpcs" class="col-sm-8"> <div class="title"> <font size="+1">Distributed Model Predictive Covariance Steering</font> </div> <div class="author"> <strong> <font color="#3B57D3"> Augustinos D. Saravanos</font> </strong>, Isin M Balci, Efstathios Bakolas, and Evangelos Theodorou</div> <div class="periodical"> <em> <font color="#104393">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) </font> </em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2212.00398" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=Hks-0BRozxA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> <div class="abstract hidden"> <p>This paper proposes Distributed Model Predictive Covariance Steering (DMPCS), a novel method for safe multi-robot control under uncertainty. The scope of our approach is to blend covariance steering theory, distributed optimization and model predictive control (MPC) into a single methodology that is safe, scalable and decentralized. Initially, we pose a problem formulation that uses the Wasserstein distance to steer the state distributions of a multi-robot team to desired targets, and probabilistic constraints to ensure safety. We then transform this problem into a finite-dimensional optimization one by utilizing a disturbance feedback policy parametrization for covariance steering and a tractable approximation of the safety constraints. To solve the latter problem, we derive a decentralized consensus-based algorithm using the Alternating Direction Method of Multipliers (ADMM). This method is then extended to a receding horizon form, which yields the proposed DMPCS algorithm. Simulation experiments on large-scale problems with up to hundreds of robots successfully demonstrate the effectiveness and scalability of DMPCS. Its superior capability in achieving safety is also highlighted through a comparison against a standard stochastic MPC approach.</p> </div> </div> </div> </li> 
<li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge" style="width: 120px;">IEEE Transactions <br> on Robotics </abbr></div> <div id="saravanos2022distributed_ddp" class="col-sm-8"> <div class="title"> <font size="+1">Distributed Differential Dynamic Programming Architectures for Large-Scale Multi-Agent Control</font> </div> <div class="author"> <strong> <font color="#3B57D3"> Augustinos D. Saravanos</font> </strong>, Yuichiro Aoyama, Hongchang Zhu, and Evangelos A Theodorou</div> <div class="periodical"> <em> <font color="#104393">IEEE Transactions on Robotics (In Submission) </font> </em>, 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2207.13255" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=tluvENcWldw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we propose two novel decentralized optimization frameworks for multi-agent nonlinear optimal control problems in robotics. The aim of this work is to suggest architectures that inherit the computational efficiency and scalability of Differential Dynamic Programming (DDP) and the distributed nature of the Alternating Direction Method of Multipliers (ADMM). In this direction, two frameworks are introduced. The first one called Nested Distributed DDP (ND-DDP), is a three-level architecture which employs ADMM for enforcing a consensus between all agents, an Augmented Lagrangian layer for satisfying local constraints and DDP as each agent’s optimizer. In the second approach, both consensus and local constraints are handled with ADMM, yielding a two-level architecture called Merged Distributed DDP (MD-DDP), which further reduces computational complexity. Both frameworks are fully decentralized since all computations are parallelizable among the agents and only local communication is necessary. Simulation results that scale up to thousands of vehicles and hundreds of drones verify the effectiveness of the methods. Superior scalability to large-scale systems against centralized DDP and centralized/decentralized sequential quadratic programming is also illustrated. Finally, hardware experiments on a multi-robot platform demonstrate the applicability of the proposed algorithms, while highlighting the importance of optimizing for feedback policies to increase robustness against uncertainty. <a href="https://youtu.be/tluvENcWldw" target="_blank" rel="noopener noreferrer">A video with all results is available here</a>.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RSS 2022 </abbr></div> <div id="pereira2022decentralized" class="col-sm-8"> <div class="title"> <font size="+1">Decentralized Safe Multi-agent Stochastic Optimal Control using Deep FBSDEs and ADMM</font> </div> <div class="author"> Marcus A. Pereira*, <strong> <font color="#3B57D3"> Augustinos D. Saravanos*</font> </strong>, Oswin So, and Evangelos A. Theodorou</div> <div class="periodical"> <em> <font color="#104393">Robotics: Science and Systems 2022 (*Equal Contribution) </font> </em>, 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.roboticsproceedings.org/rss18/p055.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=qjPLUlaxJos" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> <div class="abstract hidden"> <p>In this work, we propose a novel safe and scalable decentralized solution for multi-agent control in the presence of stochastic. Safety is mathematically encoded using stochastic control barrier functions and safe controls are computed by solving quadratic programs. Decentralization is achieved by augmenting to each agent’s optimization variables, copy variables, for its neighboring agents. This allows us to decouple the centralized multi-agent optimization problem. However, to ensure safety, neighboring agents must agree on what is safe for both of us and this creates a need for consensus. To enable safe consensus solutions, we incorporate an ADMM-based approach. Specifically, we propose a Merged CADMM-OSQP implicit neural network layer, that solves a mini-batch of both, local quadratic programs as well as the overall consensus problem, as a single optimization problem. This layer is embedded within a Deep FBSDEs network architecture at every time step, to facilitate end-to-end differentiable, safe and decentralized stochastic optimal control. The efficacy of the proposed approach is demonstrated on several challenging multi-robot tasks in simulation. By imposing requirements on safety specified by collision avoidance constraints, the safe operation of all agents is ensured during the entire training process. We also demonstrate superior scalability in terms of computational and memory savings as compared to a centralized approach.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RSS 2022 <br> SRL Workshop </abbr></div> <div id="pereira2022sim2real" class="col-sm-8"> <div class="title"> <font size="+1">Sim2Real on the Robotarium Platform Using Decentralized Multi-Agent Safe Deep FBSDEs</font> </div> <div class="author"> Marcus A. Pereira*, <strong> <font color="#3B57D3"> Augustinos D. Saravanos*</font> </strong>, and Evangelos A. Theodorou</div> <div class="periodical"> <em> <font color="#104393">Robotics: Science and Systems 2022: Workshop on Scaling Robot Learning (*Equal Contribution) </font> </em>, 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://drive.google.com/file/d/1o5BmSE1nQELEX8MEWFxIHtn_usvRGF8G/view" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=3SvrluLq4ic" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> <a href="https://www.youtube.com/watch?v=v2tb0Znh6lw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video 2</a> </div> <div class="abstract hidden"> <p>In this work, we propose a novel sim2real framework for multi-robot control that relies on stochastic optimal control theory. Specifically, we use a recently proposed Deep Forward-Backward Stochastic Differential Equations (FBSDEs) algorithm to train LSTM-network-based feedback policies in simulation that are subsequently deployed directly on real hardware. This particular Deep FBSDE variant is tailored for multi-agent systems and ensures safety during the entire training process. Safety is facilitated by employing stochastic control barrier functions and decentralization is achieved by an ADMM-based consensus optimization approach. By randomizing the initial conditions and inducing noise into the robot’s dynamics, the policy is trained to control a mini-batch of trajectories to their respective targets on average, while ensuring safety for each trajectory with probability 1. We hypothesize that the ability to control an ensemble of trajectories empowers the feedback policy to compensate for uncertainty when transferred from simulation to real robots. We test this hypothesis on the Robotarium swarm-robotics testbed and successfully demonstrate the completion of tasks as well as safe operation when a policy trained in simulation is deployed without any prior real-world experience. </p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">RSS 2021 </abbr></div> <div id="saravanos2021distributed" class="col-sm-8"> <div class="title"> <font size="+1">Distributed Covariance Steering with Consensus ADMM for Stochastic Multi-Agent Systems</font> </div> <div class="author"> <strong> <font color="#3B57D3"> Augustinos D. Saravanos</font> </strong>, Alexandros Tsolovikos, Efstathios Bakolas, and Evangelos Theodorou</div> <div class="periodical"> <em><font color="#104393"> Proceedings of Robotics: Science and Systems</font> </em>, 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://www.roboticsproceedings.org/rss17/p075.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://www.youtube.com/watch?v=RiLQ2P1WXHQ" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a> </div> <div class="abstract hidden"> <p>In this paper, we address the problem of steering a team of agents under stochastic linear dynamics to prescribed final state means and covariances. The agents operate in a common environment where inter-agent constraints may also be present. In order for our method to be scalable to large-scale systems and computationally efficient, we approach the problem in a distributed control framework using the Alternating Direction Method of Multipliers (ADMM). Each agent solves its own covariance steering problem in parallel, while additional copy variables for its closest neighbors are introduced to ensure that the inter-agent constraints will be satisfied. The inclusion of these additional variables creates a requirement for consensus between original and copy variables that involve the same agent. For this reason, we employ a variation of ADMM for consensus optimization. Simulation results on multi-vehicle systems under uncertainty with collision avoidance constraints illustrate the effectiveness of our algorithm. The substantially improved scalability of our distributed approach with respect to the number of agents is also demonstrated, in comparison with an equivalent centralized scheme.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CDC 2021 </abbr></div> <div id="aoyama2021receding" class="col-sm-8"> <div class="title"> <font size="+1">Receding Horizon Differential Dynamic Programming Under Parametric Uncertainty</font> </div> <div class="author"> Yuichiro Aoyama, <strong> <font color="#3B57D3"> Augustinos D. Saravanos</font> </strong>, and Evangelos A. Theodorou</div> <div class="periodical"> <em><font color="#104393"> 2021 60th IEEE Conference on Decision and Control (CDC)</font> </em>, 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9683370" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Generalized Polynomial Chaos (gPC) theory has been widely used for representing parametric uncertainty in a system, thanks to its ability to propagate uncertainty evolution. In an optimal control context, gPC can be combined with several optimization techniques to achieve a control policy that handles effectively this type of uncertainty. Such a suitable method is Differential Dynamic Programming (DDP), leading to an algorithm that inherits the scalability to high-dimensional systems and fast convergence nature of the latter. In this paper, we expand this combination aiming to acquire probabilistic guarantees on the satisfaction of nonlinear constraints. In particular, we exploit the ability of gPC to express higher order moments of the uncertainty distribution - without any Gaussianity assumption - and we incorporate chance constraints that lead to expressions involving the state covariance. Furthermore, we demonstrate that by implementing our algorithm in a receding horizon fashion, we are able to compute control policies that effectively reduce the accumulation of uncertainty on the trajectory. The applicability of our method is verified through simulation results on a differential wheeled robot and a quadrotor that perform obstacle avoidance tasks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">University <br> of Patras </abbr></div> <div id="saravanos2019diploma_thesis" class="col-sm-8"> <div class="title"> <font size="+1">Nonlinear Model Predictive Control for Space Robotic Systems</font> </div> <div class="author"> <strong> <font color="#3B57D3"> Augustinos D. Saravanos</font> </strong> </div> <div class="periodical"> <em><font color="#104393"> University of Patras</font> </em>, 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://nemertes.library.upatras.gr/items/e753b158-5f67-4db5-8aa0-d6725dd5ba97" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The number of satellites orbiting around the earth is continuously increasing. All these satellites demand servicing and refueling, otherwise they can become space debris. Hence, the development of space manipulators that would capture, service and decommission these satellites has become urgent. This kind of space robotic systems present many complexities while their control design has to be robust, accurate and as computationally light as possible. In this context, the objective of this thesis is the development of a Model Predictive Controller (MPC) for a robotic spacecraft/manipulator robotic system. In particular, we aim to investigate the performance of established linear MPC methods on a complex nonlinear system such as the space robotic system of this thesis. A MPC requires a model of the system in order to generate predictions about the future behaviour of the system and decide the control input that will be applied. An efficient state estimator is essential in order for the MPCs that have been developed to function properly, thus two have been designed: an Extended Kalman Filter (EKF) and a Nonlinear Moving Horizon Estimation (NMHE) algorithm. The NMHE employs an optimization-based approach taking into account past measurements for a certain horizon and using a model based on which it calculates the state estimates that agree the most with the measurements. The MHE and MPC are closely related methods since they operate in a receding horizon fashion and require a model of the system. The first MPC algorithm that has been implemented is a basic Generalized Predictive Controller (GPC). The second one is more advanced and is referred to as Dual-Mode MPC. The first part of the simulation results illustrate that in most cases the NMHE algorithm is superior to the EKF. Therefore, the NMHE has been integrated to the MPCs that have been developed. The second part of the comparative study demonstrates a comparison between the Dual-Mode MPC, the GPC and a baseline MIMO PID controller that has been designed in order to be a basis of comparison with the two MPCs. The simulation results indicate that the Dual-Mode MPC is clearly more preferable than the other two controllers. Finally, we make some conclusions with the most important being that the Dual-Mode MPC was an effective controller for the complex space robotic system it was applied on, and therefore, we suggest the application of established linear MPC techniques on nonlinear systems.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Augustinos (Augustine) Saravanos. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
